{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating Astronomical Images\n",
    "<img src='images/logo.png' width=\"300\" height=\"300\" align='right'>\n",
    "This tutorial will step you through the basic procedure to calibrate a raw astronomical image taken with the Thacher Observatory's science camera. You will need to have a local version of the Thacher Astronomy repositories and have those repositories along your python path for this notebook to work. \n",
    "\n",
    "Before we get into the code, here is a quick primer on calibrations for any charge coupled device (or CCD) camera and why they are necessary. The text has been lifted heavily from [Howell (2006, chapter 4)](http://adsabs.harvard.edu/abs/2006hca..book.....H).\n",
    "\n",
    "### Bias:\n",
    "Every camera offsets the zero level so that the A/D converter never outputs a negative number. This offset is different for every camera and every camera setting (for those cameras with changeable settings). This \"bias\" value is not necessarily constant for every pixel and must be measured so that it can be subtracted from the raw science frame.\n",
    "\n",
    "The bias image has an exposure time of zero seconds. The shutter remains closed and the CCD is simply read out. The purpose of a bias or zero frame is to allow the user to determine the underlying noise level within each data frame. The bias value in a CCD image is usually a low spatial frequency variation throughout the array, caused by the CCD on-chip amplifiers. This variation should remain constant with time. The rms value of the bias level is the CCD read noise. A bias frame contains both the DC offset level (overscan) and the variations on that level. The nature of the bias variations for a given CCD are usually column-wise variations, but may also have small row-wise components as well. Thus, a 2-D, pixel-by-pixel subtraction is often required. A single bias frame will not sample these variations well in a statistical fashion, so an average bias image of 10 or more single bias frames is recommended.\n",
    "\n",
    "### Dark:\n",
    "Photons are emitted from every body with a non-zero temperature (on the Kelvin scale). Therefore everything emits light, even your camera. These thermal photons can cause a signal in a sensitive CCD camera and therefore the rate at which this occurs needs to be accounted for in a fully calibrated image. \n",
    "\n",
    "CCD dark frames are images taken with the shutter closed but for some time period, usually equal to that of your target frames. That is, if one is planning to dark correct a 45 second exposure, a 45 second dark frame would typically be obtained. Longer dark frames can often be avoided using the assumption that the dark current increases linearly with time and a simple scaling can be applied. However, this is not always true. Dark frames are a method by which the thermal noise (dark current) in a CCD can be measured. They also can give you information about bad or \"hot\" pixels that exist as well as provide an estimate of the rate of cosmic ray strikes at your observing site. Observatory class CCD cameras are usually cooled with liquid nitrogen to temperatures at which the dark current is essentially zero. Many of these systems therefore do not require the use of dark exposure CCD frames in the calibration process. Thermoelectrically cooled systems are typically not cooled to low enough temperatures such that one may ignore the dark current, but they are getting better. In addition, these less expensive models often have poor temperature stability allowing the dark current to wander a bit with time. Multiple darks averaged together are the best way to produce the final dark calibration frame. Note that the bias is also present in dark frames. To get an accurate measure of the dark current, the bias must be subtracted.\n",
    "\n",
    "### Flat:\n",
    "Not every pixel in a CCD camera responds to the sky in the exact same way. There are many reasons for this. For one, not every pixel is created equally, so there may be some intrinsic sensitivity difference from pixel to pixel. However, the CCD may be obscured slightly by the optics of the telescope, or by dust on the camera or filters. Therefore this pixel-to-pixel variation must also be accounted for.\n",
    "\n",
    "Flat field exposures are used to correct for pixel-to-pixel variations in the CCD response as well as any nonuniform illumination of the detector itself. Flat fields expose the CCD to light from either a dome screen, the twilight sky, the nighttime sky, or a projector lamp in an attempt to provide a high signal-to-noise ratio (SNR) uniformly illuminated calibration image. For narrow-band imaging, flats are very helpful in removing fringing, which may occur in object frames. Flat field calibration frames are needed for each color, wavelength region, or different instrumental setup used in which object frames are to be taken. A good flat should remain constant to about l%, with 2% or larger changes being indicators of a possible problem. As with the other calibration frames, at least 5 or more flat fields should be taken and averaged to produce the final flat used for image calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we begin by importing some very useful packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and matplotlib, you will get used to these packages.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Astropy utilities\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# Some other packages that are real useful\n",
    "import glob\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Here we change some global plotting parameters.\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "mpl.rcParams['image.cmap'] = 'Greys_r'\n",
    "\n",
    "# run the %matplotlib magic command to enable inline plotting in the current Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we shall load our \"bias\" frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfiles = glob.glob('data/calibration/Bias*fts')\n",
    "bct = len(bfiles)\n",
    "print('There were '+str(bct)+' bias files read')\n",
    "print('The file names are:')\n",
    "for bf in bfiles:\n",
    "    print(bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These bias frames can be stacked, and the median value of each pixel is taken from the stack of bias frames to determine the \"master\" bias frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get a test image to find the dimensions\n",
    "image = fits.getdata(bfiles[0])\n",
    "ysz,xsz = image.shape\n",
    "print('Image dimensions are '+str(ysz)+' by '+str(xsz))\n",
    "stack = np.zeros((bct,ysz,xsz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(desc = 'Loading bias images', total = bct, unit = 'file')\n",
    "for i in range(bct):\n",
    "    image = fits.getdata(bfiles[i])\n",
    "    stack[i,:,:] = image\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "print('Finding median pixel values...')\n",
    "bias = np.median(stack,axis=0)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the bias frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "plt.imshow(bias,vmin=np.median(bias)-2*np.std(bias),vmax=np.median(bias)+5*np.std(bias))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a master dark frame. Notice that we need the master bias to create a master dark because each dark frame has the bias in it. So, to get an accurate measurement of the \"dark current,\" we need to subtract the bias off of each dark frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles = glob.glob('data/calibration/Dark*fts')\n",
    "dct = len(dfiles)\n",
    "print('There were '+str(dct)+' dark files read')\n",
    "print('The file names are:')\n",
    "for df in dfiles:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions of the dark frame (better be the same as the bias!)\n",
    "image = fits.getdata(dfiles[0])\n",
    "ysz,xsz = image.shape\n",
    "print('Image dimensions are '+str(ysz)+' by '+str(xsz))\n",
    "stack = np.zeros((dct,ysz,xsz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we make the dark frame such that the units are counts per second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(desc = 'Loading bias images', total = dct, unit = 'file')\n",
    "for i in range(dct):\n",
    "    image,header = fits.getdata(dfiles[i],header=True)\n",
    "    stack[i,:,:] = (image - bias)/header['EXPTIME']\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "print('Finding median pixel values...')\n",
    "dark = np.median(stack,axis=0)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the dark frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "plt.imshow(dark,vmin=np.median(dark)-2*np.std(dark),vmax=np.median(dark)+5*np.std(dark))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our last calibration, we create a master flat field. Since these images were taken with a finite integration time, we need to use both our bias and our dark frames. Only with these can the true pixel-to-pixel sensitivities be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffiles = glob.glob('data/calibration/M51*flat*fit')\n",
    "fct = len(ffiles)\n",
    "print('There were '+str(fct)+' flat files read')\n",
    "print('The file names are:')\n",
    "for ff in ffiles:\n",
    "    print(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions of the flat frames (better be the same as both the bias and the dark!)\n",
    "image = fits.getdata(ffiles[0])\n",
    "ysz,xsz = image.shape\n",
    "print('Image dimensions are '+str(ysz)+' by '+str(xsz))\n",
    "stack = np.zeros((fct,ysz,xsz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the flat is \"normalized\" so that the median value in the frame is 1.0 (or 100% sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(desc = 'Loading bias images', total = fct, unit = 'file')\n",
    "for i in range(fct):\n",
    "    image,header = fits.getdata(ffiles[i],header=True)\n",
    "    stack[i,:,:] = image - bias - dark*header['EXPTIME']\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "print('Finding median pixel values...')\n",
    "flat = np.median(stack,axis=0)\n",
    "flat /= np.median(flat)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the flat frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "plt.imshow(flat,vmin=np.median(flat)-2*np.std(flat),vmax=np.median(flat)+5*np.std(flat))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to look at our target image. Later, we will learn how to stack many images together to obtain a higher fidelity image. But for now we will look at a single image in our stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfiles = glob.glob('data/calibration/M51*solved.fits')\n",
    "tct = len(tfiles)\n",
    "print('There were '+str(tct)+' target files read')\n",
    "print('The file names are:')\n",
    "for tf in tfiles:\n",
    "    print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the middle file in this sequence to calibrate and view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target,header = fits.getdata(tfiles[tct//2],header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the raw image. You may be able to see some of the artifacts from either the bias, dark or flat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "im = target\n",
    "plt.imshow(im,vmin=np.median(im)-2*np.std(im),vmax=np.median(im)+3*np.std(im))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can see that it is M51, but there are clearly some calibration issues. Let's first take the bias out and look at the partially calibrated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "im = target-bias\n",
    "plt.imshow(im,vmin=np.median(im)-2*np.std(im),vmax=np.median(im)+3*np.std(im))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't really look any better, but the pixel values are sure different.\n",
    "\n",
    "Next, let's subtract the dark current AND the bias. Here is a subtlety worth noting. The dark current is given in counts **per second**. Therefore, to properly calibrate the image we need to subtract the dark current frame times the exposure time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "im = target-bias-dark*header['EXPTIME']\n",
    "plt.imshow(im,vmin=np.median(im)-2*np.std(im),vmax=np.median(im)+3*np.std(im))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! However, we can still see some artifacts like the dust that is obscuring the frame around pixel (1900,1250). This is what the flat field is for. Let's now take a look at a fully calibrated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = (target-bias-dark*header['EXPTIME'])/flat\n",
    "plt.figure(1,figsize=(8,8))\n",
    "plt.imshow(cal,vmin=np.median(cal)-2*np.std(cal),vmax=np.median(cal)+3*np.std(cal))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Now let's write out our final image to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto('data/calibration/M51_single_cal.fits',cal,header,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a fully calibrated image! Let's not stop there. Below are a sequence of commands that allow us to visualize our final image in a professional way, with grid lines of Right Ascension and Declination. The code is annotated so that you may understand how it works and can modify it to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stretch limits \n",
    "siglo=0.5\n",
    "sighi=5\n",
    "clipmin = np.median(cal)-siglo*np.std(cal)\n",
    "clipmax = np.median(cal)+sighi*np.std(cal)\n",
    "\n",
    "# Read in the orientation of the image\n",
    "wcs = WCS(header)\n",
    "\n",
    "# Make a plot\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.subplot(projection=wcs)\n",
    "plt.imshow(cal, vmin=clipmin, vmax=clipmax, origin='lower')\n",
    "plt.grid(color='white', ls='dotted')\n",
    "plt.xlabel('Right Ascension (J2000)',size=15)\n",
    "plt.ylabel('Declination (J2000)',size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "1. Now that you have a beautiful image, figure out how to save the image to your disk and submit your final image as a jpeg file as evidence that you know how to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
